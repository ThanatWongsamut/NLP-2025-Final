{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d848b758",
   "metadata": {},
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d601e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanat/anaconda3/envs/py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, Gemma3ForConditionalGeneration\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd04ce",
   "metadata": {},
   "source": [
    "# Loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc4fec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [01:23<00:00, 16.62s/it]\n"
     ]
    }
   ],
   "source": [
    "GEMMA_PATH = \"google/gemma-3-12b-it\"\n",
    "\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    GEMMA_PATH,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation='eager',\n",
    "    # load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ").eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(GEMMA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa441d",
   "metadata": {},
   "source": [
    "# Loading and processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c465ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, Dataset\n",
    "\n",
    "train_dataset = load_from_disk(\"processed_data/train\")\n",
    "val_dataset = load_from_disk(\"processed_data/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd1219ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 1095\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83142ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that answers questions about meeting transcripts.\n",
      "\n",
      "Meeting Transcript:\n",
      "Grad E: Right .\n",
      "Postdoc A: Mm - hmm .\n",
      "Professor C: and then it 's IBM .\n",
      "Postdoc A: Mm - hmm , mm - hmm .\n",
      "Grad E: Right .\n",
      "Professor C: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .\n",
      "Postdoc A: And have them fix it over the entire meeting too ?\n",
      "Grad E: Right .\n",
      "Professor C: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .\n",
      "Postdoc A: OK .\n",
      "Professor C: Right ?\n",
      "PhD B: As of what point ? I mean . The {disfmarker} I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their {disfmarker}\n",
      "Professor C: Why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them {disfmarker} I mean i are we trying to get something done by the time Brian comes ?\n",
      "\n",
      "\n",
      "Question: What was said about IBM? \n",
      "\n",
      "Answer the question based ONLY on the information provided in the transcript.\n",
      "Be concise and factual. If the information is not in the transcript, say \"The transcript does not provide this information.\"\n",
      "\n",
      "=================\n",
      "One meeting recording has been channelized and pre-segmented for delivery to IBM. A subset of Meeting Recorder data will be prepared (i.e. pre-segmented and manually adjusted) for delivery to IBM. \n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['prompt'][0])\n",
    "\n",
    "print(\"=================\")\n",
    "\n",
    "print(train_dataset['completion'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d8358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style=\"\"\"{}\n",
    "\n",
    "\n",
    "Answer: {}\n",
    "\"\"\"\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    prompts = examples[\"prompt\"]\n",
    "    completions = examples[\"completion\"]\n",
    "    texts = []\n",
    "    for prompt, completion in zip(prompts, completions):\n",
    "        # Append the EOS token to the response if it's not already there\n",
    "        if not completion.endswith(tokenizer.eos_token):\n",
    "            completion += tokenizer.eos_token\n",
    "        text = train_prompt_style.format(prompt, completion)\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d8a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that answers questions about meeting transcripts.\n",
      "\n",
      "Meeting Transcript:\n",
      "Grad E: Right .\n",
      "Postdoc A: Mm - hmm .\n",
      "Professor C: and then it 's IBM .\n",
      "Postdoc A: Mm - hmm , mm - hmm .\n",
      "Grad E: Right .\n",
      "Professor C: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .\n",
      "Postdoc A: And have them fix it over the entire meeting too ?\n",
      "Grad E: Right .\n",
      "Professor C: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .\n",
      "Postdoc A: OK .\n",
      "Professor C: Right ?\n",
      "PhD B: As of what point ? I mean . The {disfmarker} I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their {disfmarker}\n",
      "Professor C: Why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them {disfmarker} I mean i are we trying to get something done by the time Brian comes ?\n",
      "\n",
      "\n",
      "Question: What was said about IBM? \n",
      "\n",
      "Answer the question based ONLY on the information provided in the transcript.\n",
      "Be concise and factual. If the information is not in the transcript, say \"The transcript does not provide this information.\"\n",
      "\n",
      "\n",
      "\n",
      "Answer: One meeting recording has been channelized and pre-segmented for delivery to IBM. A subset of Meeting Recorder data will be prepared (i.e. pre-segmented and manually adjusted) for delivery to IBM. <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(formatting_prompts_func, batched = True,)\n",
    "val_dataset = val_dataset.map(formatting_prompts_func, batched = True,)\n",
    "print(train_dataset[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc3c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # we're doing causal LM, not masked LM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5416b4",
   "metadata": {},
   "source": [
    "# Model inference before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f700f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that answers questions about meeting transcripts.\n",
      "\n",
      "Meeting Transcript:\n",
      "Grad E: Right .\n",
      "Postdoc A: Mm - hmm .\n",
      "Professor C: and then it 's IBM .\n",
      "Postdoc A: Mm - hmm , mm - hmm .\n",
      "Grad E: Right .\n",
      "Professor C: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .\n",
      "Postdoc A: And have them fix it over the entire meeting too ?\n",
      "Grad E: Right .\n",
      "Professor C: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .\n",
      "Postdoc A: OK .\n",
      "Professor C: Right ?\n",
      "PhD B: As of what point ? I mean . The {disfmarker} I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their {disfmarker}\n",
      "Professor C: Why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them {disfmarker} I mean i are we trying to get something done by the time Brian comes ?\n",
      "\n",
      "\n",
      "Question: What was said about IBM? \n",
      "\n",
      "Answer the question based ONLY on the information provided in the transcript.\n",
      "Be concise and factual. If the information is not in the transcript, say \"The transcript does not provide this information.\"\n",
      "\n",
      "\n",
      "Answer:<eos>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[\"prompt\"][0] + \"\\n\\nAnswer:\" + tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a92f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    [train_dataset[\"prompt\"][0] + \"\\n\\nAnswer: \" + tokenizer.eos_token],\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13599263",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffb693c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that answers questions about meeting transcripts.\n",
      "\n",
      "Meeting Transcript:\n",
      "Grad E: Right .\n",
      "Postdoc A: Mm - hmm .\n",
      "Professor C: and then it 's IBM .\n",
      "Postdoc A: Mm - hmm , mm - hmm .\n",
      "Grad E: Right .\n",
      "Professor C: OK , so you might as well ha run the automatic thing over the entire meeting , and then {disfmarker} and then , uh , you would give IBM whatever was fixed .\n",
      "Postdoc A: And have them fix it over the entire meeting too ?\n",
      "Grad E: Right .\n",
      "Professor C: Well , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .\n",
      "Postdoc A: OK .\n",
      "Professor C: Right ?\n",
      "PhD B: As of what point ? I mean . The {disfmarker} I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their {disfmarker}\n",
      "Professor C: Why wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them {disfmarker} I mean i are we trying to get something done by the time Brian comes ?\n",
      "\n",
      "\n",
      "Question: What was said about IBM? \n",
      "\n",
      "Answer the question based ONLY on the information provided in the transcript.\n",
      "Be concise and factual. If the information is not in the transcript, say \"The transcript does not provide this information.\"\n",
      "\n",
      "\n",
      "Answer: The transcript indicates that the group discussed giving IBM the automatically fixed portions of the meeting transcript, potentially in stages, to fix the entire meeting. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb93f84",
   "metadata": {},
   "source": [
    "# Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting eval dataset to ChatML: 100%|██████████| 237/237 [00:00<00:00, 7966.61 examples/s]\n",
      "Adding EOS to eval dataset: 100%|██████████| 237/237 [00:00<00:00, 12426.71 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 237/237 [00:00<00:00, 237.90 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 237/237 [00:00<00:00, 12126.85 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from peft import LoraConfig\n",
    "\n",
    "# LoRA Configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=64,                           # Scaling factor for LoRA\n",
    "    lora_dropout=0.05,                       # Add slight dropout for regularization\n",
    "    r=32,                                    # Rank of the LoRA update matrices\n",
    "    bias=\"none\",                             # No bias reparameterization\n",
    "    task_type=\"CAUSAL_LM\",                   # Task type: Causal Language Modeling\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # Target modules for LoRA\n",
    ")\n",
    "\n",
    "\n",
    "# Training Arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=0.1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    peft_config=peft_config,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df8401",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8311765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2735' max='2735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2735/2735 32:09, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>3.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>3.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>2.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1096</td>\n",
       "      <td>2.611100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>1.600500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1644</td>\n",
       "      <td>1.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1918</td>\n",
       "      <td>0.747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2192</td>\n",
       "      <td>0.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2466</td>\n",
       "      <td>0.281100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214799e3",
   "metadata": {},
   "source": [
    "# Saving the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90abe21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Gemma-3-12B-QMSum-QA-v3/tokenizer_config.json',\n",
       " 'Gemma-3-12B-QMSum-QA-v3/special_tokens_map.json',\n",
       " 'Gemma-3-12B-QMSum-QA-v3/tokenizer.model',\n",
       " 'Gemma-3-12B-QMSum-QA-v3/added_tokens.json',\n",
       " 'Gemma-3-12B-QMSum-QA-v3/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_online = \"TWongsamut/Gemma-3-12B-QMSum-QA-v3\"\n",
    "new_model_local = \"Gemma-3-12B-QMSum-QA-v3\"\n",
    "model.save_pretrained(new_model_local) # Local saving\n",
    "tokenizer.save_pretrained(new_model_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350953f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00006-of-00006.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:   2%|▏         | 3.65M/241M [00:00<00:06, 36.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00006-of-00006.safetensors:   7%|▋         | 16.0M/241M [00:00<00:11, 18.8MB/s]\n",
      "model-00006-of-00006.safetensors:  10%|█         | 24.6M/241M [00:01<00:10, 20.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  11%|█         | 27.0M/241M [00:02<00:24, 8.81MB/s]\n",
      "model-00006-of-00006.safetensors:  13%|█▎        | 31.8M/241M [00:02<00:18, 11.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  14%|█▍        | 33.7M/241M [00:02<00:29, 7.06MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  23%|██▎       | 54.2M/241M [00:03<00:10, 17.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  24%|██▍       | 57.9M/241M [00:04<00:18, 9.75MB/s]\n",
      "\n",
      "model-00006-of-00006.safetensors:  25%|██▍       | 59.2M/241M [00:04<00:18, 9.90MB/s]\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  25%|██▌       | 60.6M/241M [00:04<00:17, 10.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  27%|██▋       | 64.0M/241M [00:05<00:25, 7.00MB/s]\n",
      "model-00006-of-00006.safetensors:  29%|██▉       | 70.0M/241M [00:05<00:15, 11.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  30%|██▉       | 71.6M/241M [00:06<00:24, 6.86MB/s]\n",
      "\n",
      "model-00006-of-00006.safetensors:  30%|███       | 73.1M/241M [00:06<00:24, 6.72MB/s]\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  31%|███       | 74.8M/241M [00:06<00:22, 7.28MB/s]\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  32%|███▏      | 76.5M/241M [00:07<00:20, 8.16MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  33%|███▎      | 80.0M/241M [00:07<00:26, 6.16MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00006-of-00006.safetensors:  36%|███▌      | 85.9M/241M [00:08<00:14, 10.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  36%|███▋      | 87.7M/241M [00:08<00:15, 9.93MB/s]\n",
      "model-00006-of-00006.safetensors:  37%|███▋      | 89.4M/241M [00:08<00:16, 9.28MB/s]\n",
      "model-00006-of-00006.safetensors:  38%|███▊      | 91.0M/241M [00:08<00:16, 9.23MB/s]\n",
      "model-00006-of-00006.safetensors:  39%|███▉      | 94.3M/241M [00:08<00:12, 12.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  40%|███▉      | 96.0M/241M [00:09<00:24, 6.03MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  47%|████▋     | 112M/241M [00:10<00:08, 15.3MB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  53%|█████▎    | 128M/241M [00:10<00:05, 21.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  60%|█████▉    | 144M/241M [00:11<00:03, 24.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00006-of-00006.safetensors:  66%|██████▋   | 160M/241M [00:11<00:03, 25.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  73%|███████▎  | 176M/241M [00:12<00:02, 27.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  80%|███████▉  | 192M/241M [00:12<00:01, 29.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors:  86%|████████▋ | 208M/241M [00:13<00:01, 30.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00006-of-00006.safetensors:  93%|█████████▎| 224M/241M [00:13<00:00, 25.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00006.safetensors: 100%|██████████| 241M/241M [00:14<00:00, 16.3MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:   0%|          | 16.0M/4.90G [00:00<04:58, 16.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:   1%|          | 32.0M/4.90G [00:01<03:30, 23.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   1%|          | 48.0M/4.90G [00:02<03:34, 22.6MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:   1%|▏         | 64.0M/4.90G [00:02<03:03, 26.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   2%|▏         | 80.0M/4.90G [00:03<02:44, 29.3MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:   2%|▏         | 96.0M/4.90G [00:03<02:42, 29.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:   2%|▏         | 112M/4.90G [00:04<02:31, 31.6MB/s] \n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   3%|▎         | 128M/4.90G [00:04<02:34, 30.8MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   3%|▎         | 144M/4.90G [00:05<02:31, 31.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:   3%|▎         | 160M/4.90G [00:05<02:27, 32.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   4%|▎         | 176M/4.90G [00:06<02:23, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:   4%|▍         | 192M/4.90G [00:06<02:24, 32.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:   4%|▍         | 208M/4.90G [00:06<02:20, 33.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00004-of-00006.safetensors:   5%|▍         | 224M/4.90G [00:07<02:23, 32.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   5%|▍         | 240M/4.90G [00:08<02:29, 31.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:   5%|▌         | 256M/4.90G [00:08<02:26, 31.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   6%|▌         | 272M/4.90G [00:08<02:20, 33.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:   6%|▌         | 288M/4.90G [00:09<02:23, 32.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   6%|▌         | 304M/4.90G [00:10<02:23, 32.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   7%|▋         | 320M/4.90G [00:10<02:17, 33.4MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:   7%|▋         | 325M/4.90G [00:10<02:18, 33.0MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:   7%|▋         | 329M/4.90G [00:10<02:30, 30.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   7%|▋         | 331M/4.90G [00:11<04:46, 15.9MB/s]\n",
      "model-00004-of-00006.safetensors:   7%|▋         | 336M/4.90G [00:11<04:35, 16.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:   7%|▋         | 338M/4.90G [00:12<08:16, 9.19MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:   7%|▋         | 352M/4.90G [00:13<04:47, 15.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   8%|▊         | 368M/4.90G [00:13<03:25, 22.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:   8%|▊         | 384M/4.90G [00:14<02:54, 25.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   8%|▊         | 400M/4.90G [00:14<02:36, 28.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   8%|▊         | 416M/4.90G [00:14<02:27, 30.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   9%|▉         | 432M/4.90G [00:15<02:21, 31.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   9%|▉         | 448M/4.90G [00:15<02:21, 31.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:   9%|▉         | 464M/4.90G [00:16<02:14, 33.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  10%|▉         | 489M/4.90G [00:17<03:09, 23.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  10%|█         | 494M/4.90G [00:18<05:22, 13.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  10%|█         | 496M/4.90G [00:19<05:13, 14.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  10%|█         | 498M/4.90G [00:19<08:37, 8.51MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  10%|█         | 510M/4.90G [00:19<03:57, 18.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  11%|█         | 515M/4.90G [00:20<04:31, 16.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  11%|█         | 528M/4.90G [00:20<03:48, 19.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  11%|█         | 544M/4.90G [00:21<03:03, 23.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  11%|█▏        | 560M/4.90G [00:21<02:55, 24.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  12%|█▏        | 576M/4.90G [00:22<02:37, 27.4MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  12%|█▏        | 592M/4.90G [00:22<02:28, 29.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  12%|█▏        | 608M/4.90G [00:23<02:21, 30.4MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  13%|█▎        | 624M/4.90G [00:23<02:15, 31.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  13%|█▎        | 640M/4.90G [00:24<02:10, 32.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  13%|█▎        | 656M/4.90G [00:25<02:48, 25.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  14%|█▎        | 672M/4.90G [00:25<02:37, 26.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  14%|█▍        | 688M/4.90G [00:26<02:29, 28.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  14%|█▍        | 704M/4.90G [00:26<02:21, 29.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  15%|█▍        | 720M/4.90G [00:27<02:16, 30.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  15%|█▌        | 736M/4.90G [00:27<02:19, 29.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  15%|█▌        | 752M/4.90G [00:28<02:16, 30.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  16%|█▌        | 768M/4.90G [00:28<02:12, 31.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  16%|█▌        | 784M/4.90G [00:29<02:07, 32.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  16%|█▋        | 800M/4.90G [00:29<02:03, 33.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  17%|█▋        | 816M/4.90G [00:30<02:06, 32.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  17%|█▋        | 832M/4.90G [00:30<02:06, 32.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  17%|█▋        | 848M/4.90G [00:31<02:05, 32.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  18%|█▊        | 864M/4.90G [00:31<02:00, 33.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  18%|█▊        | 880M/4.90G [00:32<02:00, 33.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  18%|█▊        | 896M/4.90G [00:32<02:00, 33.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  19%|█▊        | 912M/4.90G [00:33<02:01, 32.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  19%|█▉        | 928M/4.90G [00:33<01:59, 33.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  19%|█▉        | 944M/4.90G [00:35<03:16, 20.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  20%|█▉        | 960M/4.90G [00:35<02:50, 23.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  20%|█▉        | 976M/4.90G [00:36<02:34, 25.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  20%|██        | 992M/4.90G [00:36<02:24, 27.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  21%|██        | 1.01G/4.90G [00:37<02:14, 29.0MB/s]\n",
      "model-00004-of-00006.safetensors:  21%|██        | 1.02G/4.90G [00:37<01:43, 37.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  21%|██        | 1.03G/4.90G [00:37<02:02, 31.5MB/s]\n",
      "model-00004-of-00006.safetensors:  21%|██        | 1.04G/4.90G [00:37<01:41, 38.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  21%|██▏       | 1.05G/4.90G [00:38<02:17, 28.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  22%|██▏       | 1.06G/4.90G [00:38<02:31, 25.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  22%|██▏       | 1.09G/4.90G [00:39<02:10, 29.1MB/s]\n",
      "model-00004-of-00006.safetensors:  23%|██▎       | 1.10G/4.90G [00:40<02:10, 29.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  23%|██▎       | 1.12G/4.90G [00:40<02:20, 26.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  23%|██▎       | 1.14G/4.90G [00:41<02:09, 29.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  24%|██▎       | 1.15G/4.90G [00:41<02:11, 28.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  24%|██▍       | 1.17G/4.90G [00:42<02:11, 28.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  24%|██▍       | 1.18G/4.90G [00:42<02:04, 29.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  24%|██▍       | 1.20G/4.90G [00:43<01:59, 30.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  25%|██▍       | 1.22G/4.90G [00:43<01:51, 33.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  25%|██▌       | 1.23G/4.90G [00:44<02:01, 30.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  25%|██▌       | 1.25G/4.90G [00:44<01:57, 31.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  26%|██▌       | 1.28G/4.90G [00:45<01:31, 39.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  26%|██▌       | 1.28G/4.90G [00:45<01:57, 30.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  26%|██▋       | 1.30G/4.90G [00:46<02:16, 26.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  27%|██▋       | 1.31G/4.90G [00:46<02:00, 29.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  27%|██▋       | 1.33G/4.90G [00:47<01:52, 31.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  27%|██▋       | 1.34G/4.90G [00:47<01:50, 32.1MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  28%|██▊       | 1.36G/4.90G [00:48<01:47, 33.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  28%|██▊       | 1.38G/4.90G [00:48<01:44, 33.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  28%|██▊       | 1.39G/4.90G [00:48<01:25, 41.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  28%|██▊       | 1.39G/4.90G [00:49<01:48, 32.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  29%|██▊       | 1.41G/4.90G [00:49<01:51, 31.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  29%|██▉       | 1.42G/4.90G [00:50<01:52, 30.9MB/s]\n",
      "model-00004-of-00006.safetensors:  29%|██▉       | 1.44G/4.90G [00:50<01:25, 40.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  29%|██▉       | 1.44G/4.90G [00:50<01:50, 31.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  30%|██▉       | 1.46G/4.90G [00:51<01:59, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  30%|██▉       | 1.47G/4.90G [00:51<01:34, 36.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  30%|███       | 1.47G/4.90G [00:51<02:02, 27.9MB/s]\n",
      "model-00004-of-00006.safetensors:  30%|███       | 1.49G/4.90G [00:51<01:25, 39.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  31%|███       | 1.49G/4.90G [00:52<02:08, 26.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  31%|███       | 1.50G/4.90G [00:53<02:23, 23.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  31%|███       | 1.51G/4.90G [00:53<01:53, 29.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  31%|███▏      | 1.54G/4.90G [00:53<01:25, 39.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  32%|███▏      | 1.54G/4.90G [00:54<01:52, 29.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  32%|███▏      | 1.55G/4.90G [00:54<02:12, 25.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  32%|███▏      | 1.57G/4.90G [00:55<01:58, 28.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  33%|███▎      | 1.60G/4.90G [00:55<01:20, 41.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  33%|███▎      | 1.61G/4.90G [00:56<01:41, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  33%|███▎      | 1.62G/4.90G [00:57<02:43, 20.1MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  33%|███▎      | 1.63G/4.90G [00:57<01:49, 29.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00004-of-00006.safetensors:  33%|███▎      | 1.64G/4.90G [00:57<02:03, 26.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  34%|███▎      | 1.65G/4.90G [00:58<02:13, 24.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  34%|███▍      | 1.66G/4.90G [00:58<01:59, 27.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  34%|███▍      | 1.68G/4.90G [00:59<01:58, 27.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  35%|███▍      | 1.70G/4.90G [00:59<01:51, 28.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  35%|███▍      | 1.71G/4.90G [01:00<01:45, 30.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  35%|███▌      | 1.73G/4.90G [01:00<01:41, 31.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  36%|███▌      | 1.74G/4.90G [01:01<01:38, 31.9MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  36%|███▌      | 1.75G/4.90G [01:01<01:35, 32.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  36%|███▌      | 1.76G/4.90G [01:01<01:36, 32.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  36%|███▌      | 1.76G/4.90G [01:01<02:11, 23.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  37%|███▋      | 1.79G/4.90G [01:02<01:20, 38.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  37%|███▋      | 1.80G/4.90G [01:02<01:43, 30.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  37%|███▋      | 1.81G/4.90G [01:03<01:54, 27.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  37%|███▋      | 1.83G/4.90G [01:03<01:38, 31.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  37%|███▋      | 1.83G/4.90G [01:04<02:38, 19.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  37%|███▋      | 1.83G/4.90G [01:05<04:51, 10.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  37%|███▋      | 1.84G/4.90G [01:05<05:09, 9.90MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  38%|███▊      | 1.84G/4.90G [01:05<04:29, 11.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  38%|███▊      | 1.84G/4.90G [01:06<06:44, 7.55MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  38%|███▊      | 1.86G/4.90G [01:07<03:37, 14.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  38%|███▊      | 1.87G/4.90G [01:07<02:29, 20.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  39%|███▊      | 1.89G/4.90G [01:08<02:05, 24.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  39%|███▉      | 1.90G/4.90G [01:08<01:51, 26.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  39%|███▉      | 1.92G/4.90G [01:09<01:44, 28.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  40%|███▉      | 1.94G/4.90G [01:09<02:03, 23.9MB/s]\n",
      "model-00004-of-00006.safetensors:  40%|███▉      | 1.95G/4.90G [01:10<01:31, 32.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  40%|███▉      | 1.96G/4.90G [01:10<01:47, 27.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  40%|████      | 1.97G/4.90G [01:10<01:55, 25.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  41%|████      | 1.98G/4.90G [01:11<01:44, 27.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  41%|████      | 2.00G/4.90G [01:11<01:39, 29.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  41%|████      | 2.02G/4.90G [01:12<01:36, 29.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  41%|████▏     | 2.03G/4.90G [01:12<01:32, 31.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  42%|████▏     | 2.05G/4.90G [01:13<01:27, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  42%|████▏     | 2.06G/4.90G [01:13<01:26, 32.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  42%|████▏     | 2.08G/4.90G [01:14<01:23, 33.9MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  43%|████▎     | 2.10G/4.90G [01:14<01:22, 33.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  43%|████▎     | 2.11G/4.90G [01:15<01:25, 32.7MB/s]\n",
      "model-00004-of-00006.safetensors:  43%|████▎     | 2.13G/4.90G [01:15<01:06, 41.7MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  44%|████▎     | 2.13G/4.90G [01:15<01:19, 34.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  44%|████▍     | 2.14G/4.90G [01:16<01:29, 30.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  44%|████▍     | 2.16G/4.90G [01:16<01:24, 32.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  44%|████▍     | 2.18G/4.90G [01:17<01:23, 32.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  45%|████▍     | 2.19G/4.90G [01:17<01:24, 32.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  45%|████▌     | 2.21G/4.90G [01:18<01:23, 32.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  45%|████▌     | 2.22G/4.90G [01:18<01:21, 32.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  46%|████▌     | 2.24G/4.90G [01:19<01:56, 22.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  46%|████▌     | 2.26G/4.90G [01:20<01:44, 25.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  46%|████▋     | 2.27G/4.90G [01:21<01:50, 23.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  47%|████▋     | 2.29G/4.90G [01:21<01:42, 25.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  47%|████▋     | 2.30G/4.90G [01:22<01:34, 27.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  48%|████▊     | 2.33G/4.90G [01:22<01:10, 36.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  48%|████▊     | 2.34G/4.90G [01:23<01:24, 30.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  48%|████▊     | 2.37G/4.90G [01:23<01:04, 39.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  48%|████▊     | 2.37G/4.90G [01:24<01:25, 29.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00004-of-00006.safetensors:  49%|████▊     | 2.38G/4.90G [01:24<01:38, 25.4MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  49%|████▉     | 2.40G/4.90G [01:25<01:29, 27.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  49%|████▉     | 2.42G/4.90G [01:25<01:22, 30.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  50%|████▉     | 2.43G/4.90G [01:26<01:18, 31.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  50%|█████     | 2.46G/4.90G [01:26<00:57, 42.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  50%|█████     | 2.47G/4.90G [01:27<01:17, 31.1MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  51%|█████     | 2.48G/4.90G [01:27<01:04, 37.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  51%|█████     | 2.49G/4.90G [01:28<01:56, 20.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  51%|█████     | 2.50G/4.90G [01:28<01:53, 21.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  51%|█████▏    | 2.51G/4.90G [01:29<01:36, 24.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  52%|█████▏    | 2.53G/4.90G [01:29<01:30, 26.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  52%|█████▏    | 2.54G/4.90G [01:30<01:21, 28.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  52%|█████▏    | 2.56G/4.90G [01:30<01:22, 28.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  53%|█████▎    | 2.58G/4.90G [01:31<01:17, 30.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  53%|█████▎    | 2.59G/4.90G [01:31<01:18, 29.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  53%|█████▎    | 2.61G/4.90G [01:32<01:15, 30.4MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  54%|█████▎    | 2.62G/4.90G [01:32<00:56, 40.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  54%|█████▎    | 2.63G/4.90G [01:32<01:09, 32.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  54%|█████▍    | 2.64G/4.90G [01:33<01:22, 27.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  54%|█████▍    | 2.66G/4.90G [01:33<01:17, 29.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  55%|█████▍    | 2.67G/4.90G [01:34<01:12, 30.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  55%|█████▍    | 2.69G/4.90G [01:34<01:10, 31.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  55%|█████▌    | 2.70G/4.90G [01:35<01:15, 29.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  56%|█████▌    | 2.72G/4.90G [01:39<03:46, 9.61MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  56%|█████▌    | 2.74G/4.90G [01:39<02:55, 12.3MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  56%|█████▌    | 2.75G/4.90G [01:40<02:20, 15.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  57%|█████▋    | 2.77G/4.90G [01:40<01:57, 18.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  57%|█████▋    | 2.78G/4.90G [01:41<01:38, 21.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  57%|█████▋    | 2.80G/4.90G [01:41<01:25, 24.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  57%|█████▋    | 2.82G/4.90G [01:42<01:19, 26.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  58%|█████▊    | 2.83G/4.90G [01:42<01:14, 27.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  58%|█████▊    | 2.85G/4.90G [01:43<01:14, 27.6MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  58%|█████▊    | 2.86G/4.90G [01:43<01:10, 29.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  59%|█████▉    | 2.88G/4.90G [01:45<01:35, 21.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  59%|█████▉    | 2.90G/4.90G [01:45<01:24, 23.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  59%|█████▉    | 2.91G/4.90G [01:46<01:15, 26.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  60%|█████▉    | 2.93G/4.90G [01:46<01:09, 28.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  60%|██████    | 2.94G/4.90G [01:47<01:18, 25.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  60%|██████    | 2.96G/4.90G [01:47<01:12, 26.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  61%|██████    | 2.98G/4.90G [01:48<01:08, 27.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  61%|██████▏   | 3.01G/4.90G [01:48<00:49, 37.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  62%|██████▏   | 3.01G/4.90G [01:49<00:59, 31.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  62%|██████▏   | 3.02G/4.90G [01:49<01:06, 28.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  62%|██████▏   | 3.04G/4.90G [01:50<01:26, 21.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  62%|██████▏   | 3.06G/4.90G [01:51<01:15, 24.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  63%|██████▎   | 3.07G/4.90G [01:51<01:06, 27.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  63%|██████▎   | 3.09G/4.90G [01:52<01:02, 29.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  63%|██████▎   | 3.10G/4.90G [01:52<00:59, 30.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  64%|██████▎   | 3.12G/4.90G [01:53<00:55, 32.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  64%|██████▍   | 3.14G/4.90G [01:53<00:53, 32.9MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  64%|██████▍   | 3.15G/4.90G [01:53<00:43, 40.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  64%|██████▍   | 3.15G/4.90G [01:54<00:54, 31.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  65%|██████▍   | 3.17G/4.90G [01:54<00:57, 30.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  65%|██████▌   | 3.18G/4.90G [01:55<01:11, 24.1MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  65%|██████▌   | 3.20G/4.90G [01:55<00:50, 33.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  65%|██████▌   | 3.21G/4.90G [01:56<01:01, 27.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  66%|██████▌   | 3.23G/4.90G [01:56<00:49, 33.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  66%|██████▌   | 3.23G/4.90G [01:57<01:01, 27.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  66%|██████▋   | 3.25G/4.90G [01:57<01:03, 26.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  67%|██████▋   | 3.26G/4.90G [01:58<00:56, 28.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  67%|██████▋   | 3.28G/4.90G [01:58<00:55, 29.3MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  67%|██████▋   | 3.30G/4.90G [01:58<00:40, 39.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  67%|██████▋   | 3.30G/4.90G [01:59<00:48, 32.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  68%|██████▊   | 3.31G/4.90G [01:59<00:54, 29.3MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  68%|██████▊   | 3.33G/4.90G [02:00<00:52, 30.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  68%|██████▊   | 3.34G/4.90G [02:00<00:50, 30.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  69%|██████▊   | 3.36G/4.90G [02:00<00:37, 40.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  69%|██████▊   | 3.37G/4.90G [02:01<00:47, 32.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  69%|██████▉   | 3.38G/4.90G [02:01<00:54, 28.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  69%|██████▉   | 3.39G/4.90G [02:02<00:50, 30.1MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors:  69%|██████▉   | 3.40G/4.90G [02:02<00:39, 37.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  70%|██████▉   | 3.41G/4.90G [02:02<00:50, 29.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  70%|██████▉   | 3.42G/4.90G [02:02<00:39, 37.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  70%|██████▉   | 3.43G/4.90G [02:03<01:01, 24.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  70%|███████   | 3.44G/4.90G [02:03<00:58, 24.8MB/s]\n",
      "model-00004-of-00006.safetensors:  70%|███████   | 3.45G/4.90G [02:03<00:42, 33.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  71%|███████   | 3.46G/4.90G [02:04<00:51, 27.9MB/s]\n",
      "model-00004-of-00006.safetensors:  71%|███████   | 3.47G/4.90G [02:04<00:36, 38.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  71%|███████   | 3.48G/4.90G [02:04<00:44, 31.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  71%|███████   | 3.49G/4.90G [02:05<00:50, 28.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  72%|███████▏  | 3.50G/4.90G [02:05<00:46, 30.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  72%|███████▏  | 3.52G/4.90G [02:06<00:45, 30.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  72%|███████▏  | 3.54G/4.90G [02:06<00:43, 31.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  73%|███████▎  | 3.55G/4.90G [02:07<00:42, 32.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  73%|███████▎  | 3.57G/4.90G [02:07<00:40, 32.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  73%|███████▎  | 3.58G/4.90G [02:08<00:40, 32.5MB/s]\n",
      "model-00004-of-00006.safetensors:  73%|███████▎  | 3.60G/4.90G [02:08<00:31, 41.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  74%|███████▎  | 3.60G/4.90G [02:08<00:38, 33.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  74%|███████▍  | 3.62G/4.90G [02:09<00:44, 29.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  74%|███████▍  | 3.63G/4.90G [02:09<00:41, 30.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  74%|███████▍  | 3.65G/4.90G [02:10<00:39, 31.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  75%|███████▍  | 3.66G/4.90G [02:10<00:37, 33.2MB/s]\n",
      "model-00004-of-00006.safetensors:  75%|███████▌  | 3.68G/4.90G [02:10<00:35, 34.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  75%|███████▌  | 3.70G/4.90G [02:11<00:27, 44.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  76%|███████▌  | 3.70G/4.90G [02:11<00:35, 33.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  76%|███████▌  | 3.71G/4.90G [02:12<00:40, 29.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  76%|███████▌  | 3.73G/4.90G [02:12<00:38, 30.4MB/s]\n",
      "model-00004-of-00006.safetensors:  76%|███████▋  | 3.74G/4.90G [02:12<00:28, 40.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  77%|███████▋  | 3.75G/4.90G [02:13<00:34, 32.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  77%|███████▋  | 3.76G/4.90G [02:13<00:31, 36.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  77%|███████▋  | 3.76G/4.90G [02:13<00:41, 27.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  77%|███████▋  | 3.78G/4.90G [02:14<00:47, 23.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  77%|███████▋  | 3.79G/4.90G [02:14<00:40, 27.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  78%|███████▊  | 3.81G/4.90G [02:15<00:38, 28.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  78%|███████▊  | 3.84G/4.90G [02:15<00:26, 40.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  79%|███████▊  | 3.85G/4.90G [02:16<00:31, 33.0MB/s]\n",
      "model-00004-of-00006.safetensors:  79%|███████▊  | 3.85G/4.90G [02:16<00:28, 36.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  79%|███████▉  | 3.86G/4.90G [02:16<00:38, 27.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  79%|███████▉  | 3.87G/4.90G [02:17<00:35, 28.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  80%|███████▉  | 3.90G/4.90G [02:17<00:24, 40.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  80%|███████▉  | 3.91G/4.90G [02:18<00:29, 33.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  80%|████████  | 3.92G/4.90G [02:18<00:39, 24.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  80%|████████  | 3.94G/4.90G [02:19<00:34, 27.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  81%|████████  | 3.95G/4.90G [02:19<00:31, 30.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  81%|████████  | 3.97G/4.90G [02:20<00:28, 32.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  82%|████████▏ | 4.00G/4.90G [02:20<00:22, 39.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  82%|████████▏ | 4.00G/4.90G [02:21<00:28, 31.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  82%|████████▏ | 4.02G/4.90G [02:21<00:28, 31.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  82%|████████▏ | 4.03G/4.90G [02:22<00:30, 28.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  83%|████████▎ | 4.05G/4.90G [02:22<00:30, 27.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  83%|████████▎ | 4.06G/4.90G [02:23<00:27, 30.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  83%|████████▎ | 4.08G/4.90G [02:23<00:25, 31.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  84%|████████▎ | 4.10G/4.90G [02:24<00:24, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  84%|████████▍ | 4.13G/4.90G [02:24<00:18, 42.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  84%|████████▍ | 4.13G/4.90G [02:25<00:21, 35.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  85%|████████▍ | 4.14G/4.90G [02:25<00:22, 33.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  85%|████████▍ | 4.16G/4.90G [02:25<00:22, 33.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  85%|████████▌ | 4.18G/4.90G [02:26<00:21, 33.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  86%|████████▌ | 4.19G/4.90G [02:26<00:21, 32.3MB/s]\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  86%|████████▌ | 4.21G/4.90G [02:27<00:17, 40.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  86%|████████▌ | 4.21G/4.90G [02:27<00:21, 31.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00004-of-00006.safetensors:  86%|████████▌ | 4.22G/4.90G [02:28<00:22, 29.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  87%|████████▋ | 4.24G/4.90G [02:28<00:21, 30.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  87%|████████▋ | 4.26G/4.90G [02:29<00:20, 31.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  87%|████████▋ | 4.27G/4.90G [02:29<00:20, 30.6MB/s]\n",
      "model-00004-of-00006.safetensors:  88%|████████▊ | 4.29G/4.90G [02:29<00:14, 40.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  88%|████████▊ | 4.29G/4.90G [02:30<00:18, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  88%|████████▊ | 4.30G/4.90G [02:30<00:21, 28.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  88%|████████▊ | 4.32G/4.90G [02:31<00:19, 29.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  89%|████████▊ | 4.34G/4.90G [02:31<00:18, 30.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  89%|████████▉ | 4.35G/4.90G [02:32<00:20, 26.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  89%|████████▉ | 4.37G/4.90G [02:32<00:18, 29.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  89%|████████▉ | 4.38G/4.90G [02:33<00:17, 30.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  90%|████████▉ | 4.40G/4.90G [02:33<00:15, 31.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  90%|█████████ | 4.42G/4.90G [02:34<00:14, 32.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  90%|█████████ | 4.43G/4.90G [02:34<00:14, 33.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00006.safetensors:  91%|█████████ | 4.45G/4.90G [02:35<00:13, 33.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00001-of-00006.safetensors: 100%|██████████| 4.94G/4.94G [02:55<00:00, 28.1MB/s]\n",
      "\n",
      "\u001b[A\n",
      "model-00004-of-00006.safetensors:  91%|█████████ | 4.46G/4.90G [02:40<00:53, 8.11MB/s]\n",
      "model-00004-of-00006.safetensors:  91%|█████████▏| 4.48G/4.90G [02:40<00:39, 10.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors:  92%|█████████▏| 4.50G/4.90G [02:41<00:30, 13.3MB/s]\n",
      "model-00004-of-00006.safetensors:  92%|█████████▏| 4.51G/4.90G [02:41<00:23, 16.3MB/s]\n",
      "model-00004-of-00006.safetensors:  92%|█████████▏| 4.53G/4.90G [02:42<00:19, 19.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  93%|█████████▎| 4.54G/4.90G [02:42<00:15, 22.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  93%|█████████▎| 4.56G/4.90G [02:43<00:13, 25.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00006.safetensors:  93%|█████████▎| 4.58G/4.90G [02:43<00:12, 26.2MB/s]\n",
      "model-00005-of-00006.safetensors: 100%|██████████| 4.93G/4.93G [02:59<00:00, 27.5MB/s]\n",
      "model-00004-of-00006.safetensors:  94%|█████████▎| 4.59G/4.90G [02:44<00:10, 28.2MB/s]\n",
      "model-00004-of-00006.safetensors:  94%|█████████▍| 4.61G/4.90G [02:44<00:09, 29.5MB/s]\n",
      "model-00004-of-00006.safetensors:  94%|█████████▍| 4.62G/4.90G [02:45<00:09, 30.4MB/s]\n",
      "model-00004-of-00006.safetensors:  96%|█████████▌| 4.69G/4.90G [02:47<00:06, 30.4MB/s]\n",
      "model-00004-of-00006.safetensors:  96%|█████████▌| 4.70G/4.90G [02:47<00:06, 30.9MB/s]\n",
      "model-00004-of-00006.safetensors:  96%|█████████▋| 4.72G/4.90G [02:48<00:05, 31.8MB/s]\n",
      "model-00004-of-00006.safetensors:  97%|█████████▋| 4.75G/4.90G [02:49<00:04, 33.7MB/s]\n",
      "model-00004-of-00006.safetensors:  97%|█████████▋| 4.77G/4.90G [02:49<00:03, 34.0MB/s]\n",
      "model-00004-of-00006.safetensors:  97%|█████████▋| 4.77G/4.90G [02:50<00:07, 17.4MB/s]\n",
      "model-00004-of-00006.safetensors:  98%|█████████▊| 4.78G/4.90G [02:51<00:05, 20.7MB/s]\n",
      "model-00004-of-00006.safetensors:  98%|█████████▊| 4.80G/4.90G [02:51<00:04, 23.2MB/s]\n",
      "model-00004-of-00006.safetensors:  98%|█████████▊| 4.82G/4.90G [02:52<00:03, 27.4MB/s]\n",
      "model-00004-of-00006.safetensors:  99%|█████████▊| 4.83G/4.90G [02:52<00:02, 28.2MB/s]\n",
      "model-00004-of-00006.safetensors:  99%|█████████▉| 4.85G/4.90G [02:52<00:01, 30.8MB/s]\n",
      "model-00004-of-00006.safetensors:  99%|█████████▉| 4.86G/4.90G [02:53<00:01, 24.7MB/s]\n",
      "model-00002-of-00006.safetensors: 100%|██████████| 4.93G/4.93G [03:09<00:00, 26.0MB/s]\n",
      "\n",
      "model-00004-of-00006.safetensors: 100%|█████████▉| 4.88G/4.90G [02:54<00:00, 24.9MB/s]\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00006.safetensors: 100%|██████████| 4.99G/4.99G [03:09<00:00, 26.2MB/s]\n",
      "model-00004-of-00006.safetensors: 100%|█████████▉| 4.90G/4.90G [02:55<00:00, 26.6MB/s]\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00006.safetensors: 100%|██████████| 4.90G/4.90G [02:55<00:00, 27.9MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upload 6 LFS files: 100%|██████████| 6/6 [03:10<00:00, 31.83s/it]\n",
      "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]\n",
      "tokenizer.model: 100%|██████████| 4.69M/4.69M [00:00<00:00, 10.5MB/s]\n",
      "\n",
      "tokenizer.json: 100%|██████████| 33.4M/33.4M [00:01<00:00, 21.7MB/s]\n",
      "\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:01<00:00,  1.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/TWongsamut/Gemma-3-12B-QMSum-QA-v3/commit/88c35a30b57fc1e9374b4eecba541cc2c4a8b402', commit_message='Upload tokenizer', commit_description='', oid='88c35a30b57fc1e9374b4eecba541cc2c4a8b402', pr_url=None, repo_url=RepoUrl('https://huggingface.co/TWongsamut/Gemma-3-12B-QMSum-QA-v3', endpoint='https://huggingface.co', repo_type='model', repo_id='TWongsamut/Gemma-3-12B-QMSum-QA-v3'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(new_model_online) # Online saving\n",
    "tokenizer.push_to_hub(new_model_online) # Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15901fee",
   "metadata": {},
   "source": [
    "# Model inference after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d07aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, Gemma3ForConditionalGeneration\n",
    "\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b146ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMMA_PATH = \"Gemma-3-12B-QMSum-QA-v2\"\n",
    "\n",
    "# model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "#     GEMMA_PATH,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation='eager',\n",
    "#     # load_in_8bit=True,\n",
    "#     device_map=\"auto\",\n",
    "# ).eval()\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(GEMMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e24dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_from_disk\n",
    "\n",
    "# train_dataset = load_from_disk(\"processed_data/train\")\n",
    "# val_dataset = load_from_disk(\"processed_data/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e6c9549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that answers questions about meeting transcripts.\n",
      "\n",
      "Meeting Transcript:\n",
      "Grad E: Whereas I think it it 's probably something pathologic and actually Stephane 's results , I think confirm that . He s he did the Aurora system also got very lousy average error , like fifteen or {disfmarker} or , uh , fifteen to twenty percent average ? But then he ran it just on the lapel , and got about five or six percent word error ? So that {disfmarker} that means to me that somewhere in the other recordings there are some pathological cases . But , you know , we {disfmarker} th that may not be true . It may be just some of the segments they 're just doing a lousy job on . So I 'll {disfmarker} I 'll listen to it and find out since you 'd actually split it up by segment .\n",
      "Professor C: Right .\n",
      "Grad E: So I can actually listen to it .\n",
      "PhD F: Yeah .\n",
      "PhD B: Did you run the {disfmarker} Andreas {disfmarker} the r SRI recognizer on the digits ?\n",
      "Grad E: Oh , I thought he had sent that around to everyone ,\n",
      "PhD F: Yeah .\n",
      "Grad E: did you just sent that to me ?\n",
      "PhD F: No , I d I didn't .\n",
      "Grad E: Oh .\n",
      "PhD F: Since I considered those preliminary , I didn't .\n",
      "PhD B: I it wasn't {disfmarker}\n",
      "PhD F: But , yeah , if you take {disfmarker}\n",
      "Grad E: It was bimodal .\n",
      "PhD F: So if you {disfmarker} Yeah , it 's actually , um , it {disfmarker} uh {disfmarker} it was trimodal , actually {disfmarker}\n",
      "Grad E: Oh , was it trimodal , OK .\n",
      "Professor C: Yeah .\n",
      "PhD F: trimodal , so\n",
      "Professor C: There 's zero , a little bit , and a lot .\n",
      "PhD F: there were {disfmarker} {vocalsound} t there was {disfmarker} there was one h one bump at ze around zero , which were the native speakers ,\n",
      "Professor C: Yeah .\n",
      "PhD B: Zero percent error ?\n",
      "Professor C: Yeah .\n",
      "PhD F: the non - pathological native speakers .\n",
      "Professor C: Y yeah .\n",
      "PhD F: Then there was another bump at , um , {vocalsound} {vocalsound} oh , like fifteen or something .\n",
      "PhD B: This is error you 're talking about ?\n",
      "Professor C: Oh was it fifteen ?\n",
      "PhD F: whe\n",
      "PhD B: OK .\n",
      "Professor C: Yeah .\n",
      "Grad E: Yeah .\n",
      "PhD F: Yeah . Those were the non - natives . And then there was another distinct bump at , like , a hundred , {vocalsound} which must have been some problem .\n",
      "\n",
      "\n",
      "Question: What were the preliminary recognition results?\n",
      "\n",
      "Answer the question based ONLY on the information provided in the transcript.\n",
      "Be concise and factual. If the information is not in the transcript, say \"The transcript does not provide this information.\"\n",
      "\n",
      "\n",
      "Answer: \n",
      "Preliminary recognition results were obtained for a subset of digits data. The error rate distribution was multimodal, reflecting differences in performance for native versus non-native speakers, and also possible pre-processing errors. \n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [train_dataset[\"prompt\"][1] + \"\\n\\nAnswer: \"],\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=50,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15b10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
