EVALUATION SUMMARY REPORT
=======================

MODEL: end_to_end_gemma3:12b.csv
=====================================
   BERTScore:
      Precision: 0.6181
      Recall: 0.6145
      F1: 0.6138

   Reference-Candidate Similarity:
      Mean: 0.5775

   Query-Candidate Relevance:
      Mean: 0.5938

   Aggregated Metric:
      Mean: 0.7267

   ROUGE Metrics:
      ROUGE-1 Precision: 0.3582
      ROUGE-1 Recall: 0.3243
      ROUGE-1 F1: 0.3085

      ROUGE-2 Precision: 0.1122
      ROUGE-2 Recall: 0.0968
      ROUGE-2 F1: 0.0937

      ROUGE-L Precision: 0.2456
      ROUGE-L Recall: 0.2139
      ROUGE-L F1: 0.2057

--------------------------------------------------

MODEL: end_to_end_gemma3:12b-finetuned.csv
===============================================
   BERTScore:
      Precision: 0.6447
      Recall: 0.6401
      F1: 0.6417

   Reference-Candidate Similarity:
      Mean: 0.5761

   Query-Candidate Relevance:
      Mean: 0.5200

   Aggregated Metric:
      Mean: 0.6239

   ROUGE Metrics:
      ROUGE-1 Precision: 0.3567
      ROUGE-1 Recall: 0.3587
      ROUGE-1 F1: 0.3441

      ROUGE-2 Precision: 0.1055
      ROUGE-2 Recall: 0.1076
      ROUGE-2 F1: 0.1014

      ROUGE-L Precision: 0.2266
      ROUGE-L Recall: 0.2326
      ROUGE-L F1: 0.2199

--------------------------------------------------

MODEL: end_to_end_gemma3:27b.csv
=====================================
   BERTScore:
      Precision: 0.6189
      Recall: 0.6296
      F1: 0.6222

   Reference-Candidate Similarity:
      Mean: 0.5920

   Query-Candidate Relevance:
      Mean: 0.5605

   Aggregated Metric:
      Mean: 0.7033

   ROUGE Metrics:
      ROUGE-1 Precision: 0.3349
      ROUGE-1 Recall: 0.3562
      ROUGE-1 F1: 0.3201

      ROUGE-2 Precision: 0.0957
      ROUGE-2 Recall: 0.1001
      ROUGE-2 F1: 0.0907

      ROUGE-L Precision: 0.2217
      ROUGE-L Recall: 0.2314
      ROUGE-L F1: 0.2082

--------------------------------------------------

